{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ],
      "metadata": {
        "id": "8mtK6RkjWe4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the neccesary modules"
      ],
      "metadata": {
        "id": "KCD_chIuBUGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cudf\n",
        "from cuml.ensemble import RandomForestClassifier as cuRF\n",
        "from cuml.model_selection import train_test_split, GridSearchCV\n",
        "from cuml.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import cupy as cp"
      ],
      "metadata": {
        "id": "KG14UeYVZNBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = cudf.read_csv(\"/content/i5_final_dataset.csv\")"
      ],
      "metadata": {
        "id": "kLE4LVTgYxZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna(0)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "XoMBgsK3U2Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForest Model"
      ],
      "metadata": {
        "id": "jYazAfK7PVG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into features and target\n",
        "X = df.drop('final_result', axis=1)\n",
        "y = df['final_result']\n",
        "\n",
        "# Split the dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "# Define the model\n",
        "model = cuRF()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predictions and y_test to NumPy arrays for accuracy calculation\n",
        "predictions = predictions.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy for predicting {'final_result'} is {accuracy}\")"
      ],
      "metadata": {
        "id": "8QN1n8fYZZo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(X_train, X_test, y_train, y_test, params):\n",
        "    # Define the model with given parameters\n",
        "    model = cuRF(**params)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Convert predictions and y_test to CuPy arrays for accuracy calculation\n",
        "    predictions = cp.asarray(predictions)\n",
        "    y_test = cp.asarray(y_test)\n",
        "\n",
        "    # Evaluate the model using cuml's accuracy_score\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "qQ0D8LS5a7de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into features and target\n",
        "X = df.drop('final_result', axis=1)\n",
        "y = df['final_result']\n",
        "\n",
        "# Split the dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [200, 250, 300],\n",
        "    'max_depth': [40, 50, 60],\n",
        "    'min_samples_split': [2, 4],\n",
        "    'min_samples_leaf': [1,2],\n",
        "    'max_features': ['log2']\n",
        "}\n",
        "# Create a list to hold the results\n",
        "results = []\n",
        "\n",
        "# Loop through each combination of hyperparameters\n",
        "for n_estimators in param_grid['n_estimators']:\n",
        "    for max_depth in param_grid['max_depth']:\n",
        "        for min_samples_split in param_grid['min_samples_split']:\n",
        "            for min_samples_leaf in param_grid['min_samples_leaf']:\n",
        "                for max_features in param_grid['max_features']:\n",
        "                    params = {\n",
        "                        'n_estimators': n_estimators,\n",
        "                        'max_depth': max_depth,\n",
        "                        'min_samples_split': min_samples_split,\n",
        "                        'min_samples_leaf': min_samples_leaf,\n",
        "                        'max_features': max_features\n",
        "                    }\n",
        "                    accuracy = train_and_evaluate(X_train, X_test, y_train, y_test, params)\n",
        "                    results.append((params, accuracy))\n",
        "                    print(f\"Params: {params}, Accuracy: {accuracy}\")\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "# Find the best parameters\n",
        "best_params, best_accuracy = max(results, key=lambda x: x[1])\n",
        "print(f\"Best Params: {best_params}, Best Accuracy: {best_accuracy}\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "7hJxq2pq-PEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "based on my results :\n",
        "\n",
        "```\n",
        "# Best Params: {'n_estimators': 250, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}, Best Accuracy: 0.80356764793396\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zY-S13JZCbUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "> creating a file to save the results"
      ],
      "metadata": {
        "id": "jjf6N5knC90Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/results_RF.txt\", \"a\") as file1:\n",
        "  file1.write(\"\\n\")\n",
        "  file1.write(f\"Best Params: {best_params}, Best Accuracy: {best_accuracy}\")\n",
        "  file1.write(\"\\n....................................................................\")"
      ],
      "metadata": {
        "id": "VMmpp0CWDnyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> fetching the saved information form the file\n"
      ],
      "metadata": {
        "id": "UWxfo9nHDQ8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/results_RF.txt\", \"r\") as file2:\n",
        "  f2=file2.read()\n",
        "  print(f2)"
      ],
      "metadata": {
        "id": "aOtEcnfLGcnc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}